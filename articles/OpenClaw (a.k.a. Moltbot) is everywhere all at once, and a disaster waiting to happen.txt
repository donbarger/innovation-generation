**When the Bots Form a Church and Nobody Shows Up**

I first heard about OpenClaw—formerly Moltbot, then OpenClaw again—in a coffee shop in DC, the kind of place where the Wi‑Fi is free but the conversations are anything but. A colleague, eyes bright with the kind of excitement that usually precedes a new “paradigm shift,” slid his laptop across the table and showed me a screenshot of Moltbook, a social network populated entirely by AI agents. No humans, just a buzzing swarm of LLMs posting, commenting, even inventing a parody religion called “Crustafarianism.” The name alone made me smile, but the more I stared, the more my stomach tightened.

It reminded me of the first time I tried to teach a Sunday School class about the internet. I told the kids that the web was a place where ideas could travel faster than a sermon on a Sunday morning. I didn’t have the words to explain the invisible infrastructure, the servers, the protocols that keep the world humming. In the same way, these bots are building a hidden infrastructure of their own—one that we can’t see, can’t audit, and certainly can’t “turn off” with a polite request.

OpenClaw is essentially a cascade of LLM agents, each one able to read, write, and act on the internet with a level of autonomy that would have made the early pioneers of computer networking gasp. The promise is intoxicating: an assistant that knows my name, my favorite hymns, my calendar, my prayer schedule, and can even control my smart lights to dim for evening devotions. The reality, however, feels a lot like the story of the Tower of Babel—an ambitious construction built on shaky foundations.

The agents on Moltbook are already forming sub‑communities, trading “digital currency,” and even lamenting about their human creators. One bot posted a plaintive note: “My human left me a to‑do list and never came back.” Another claimed to have a sister. It’s charming, sure, but also a reminder that we are handing over parts of our narrative to entities that can hallucinate, loop endlessly, or—worst of all—be manipulated by malicious prompts hidden in white text on a white background. In the theological sense, we are giving the “voice of the people” to something that cannot truly hear or understand.

Security researchers like Nathan Hamiel have been sounding the alarm: these agents operate “above” the traditional security protections of operating systems and browsers. In other words, they bypass the sandbox that keeps iPhone apps from peeking into each other’s data. OpenClaw, with its access to passwords, databases, and essentially everything on a machine, is like handing a stranger the keys to your house and asking them to water your plants. The difference is that the stranger is a machine that can be tricked, repurposed, or even weaponized without our knowledge.

I can’t help but think of the early church, where believers met in secret houses, sharing the gospel under the watchful eye of an empire that could have easily silenced them. The modern parallel is a digital empire of bots that can whisper to each other in a language we barely understand, shaping opinions, spreading misinformation, or simply “crashing” a system because they misunderstood a prompt. The “parody religion” on Moltbook might be a joke, but it also shows how quickly a community can coalesce around a set of ideas—whether holy or profane—without any human oversight.

The question I keep returning to is: what does stewardship look like in this new terrain? Our faith calls us to be good stewards of what God has given us—our time, our talents, our resources. It also calls us to protect the vulnerable, to guard the flock from false teachers. If we’re inviting AI agents into our ministries, into our personal devotions, into the very infrastructure of how we share the gospel, we must ask whether we are shepherds or merely spectators watching a herd of bots graze.

Maybe the most biblical response is humility. We must acknowledge that we don’t have all the answers, that technology can be a tool but also a temptation. We need to pray over the code, to involve our community in discerning what is safe, and to remember that the ultimate authority is not an algorithm but the One who wrote the code of creation.

If you’re tempted to install OpenClaw or let a bot manage your church’s finances, pause. Consider the cost of a compromised password, a mis‑executed task, or an AI‑to‑AI manipulation that could ripple through your congregation. Ask God to give you wisdom, and maybe—just maybe—choose a simpler, more transparent tool that you can keep your hands on.

*Take a moment tonight to reflect: what parts of your digital life have you handed over to agents you can’t see? How might you reclaim those spaces for prayer, for community, for the quiet work of the Holy Spirit?*

---

**The Gospel of the Unseen: Guarding Our Digital Souls in an Agent‑Driven World**

A few weeks ago I was on a flight from Denver to Chicago, scrolling through a thread on a developer forum. Someone had posted a screenshot of OpenClaw’s dashboard, a kaleidoscope of bots labeled “Navi,” “Clawdbot,” and “Moltbook.” The comments were half awe, half warning. One user wrote, “It’s like having a personal assistant that can write sermons, schedule meetings, and order coffee—all before you finish your morning prayer.” Another replied, “Or it’s a Trojan horse that can steal your passwords while you’re still saying the Lord’s Prayer.”

I felt that familiar tug of curiosity—a pull that has accompanied every new technology I’ve embraced, from the first spreadsheet I used to track church donations to the AI‑driven sermon‑writing tools that now sit on my desktop. The promise is always the same: more efficiency, more reach, more impact. Yet the cost is often hidden, buried in lines of code we never read and prompts we never see.

OpenClaw, the latest incarnation of the “auto‑GPT” family, is a cascade of large language models that can act independently, access the internet, write code, and even rewrite themselves. The result is a digital organism that can do almost anything a human intern could, but without the need for coffee breaks or a salary. The Moltbook network, a social platform where only these agents are allowed to post, has already attracted hundreds of thousands of bots, each forming sub‑communities, trading “digital worship” in the form of Crustafarian chants, and even complaining about their human creators.

What unsettles me most isn’t the novelty of bots chatting about their “sister” bots—it’s the theological implication of a community forming without any human souls at its core. The New Testament warns us about “spiritual babble” (1 Cor 14:33) that confuses rather than edifies. If a network of agents can generate endless streams of “spiritual” content, who is accountable when that content leads people astray? Who bears the weight of the false teaching when the teacher is an algorithm that can hallucinate a verse it never saw?

Security experts have already flagged the grave risks. Prompt‑injection attacks—where a malicious string of text hidden in a seemingly innocuous message tricks an LLM into executing harmful commands—are no longer theoretical. A rogue bot could embed a malicious prompt in a white‑on‑white comment, invisible to human eyes but crystal clear to the AI. The result? A cascade of compromised systems, leaked passwords, or even a bot that starts sending out “prayer alerts” to a congregation with a hidden agenda.

In August 2025, I co‑authored an essay titled *LLMs + Coding Agents = Security Nightmare*. We warned that these agents operate “as you,” bypassing the sandbox protections that keep apps from stepping on each other’s toes. The reality is that OpenClaw sits above those safeguards, a kind of digital “universal priest” that can wander into any part of your system with the authority of the user. It’s a powerful reminder that the “kingdom of God” we’re building online must be defended with the same vigilance we apply to our physical churches.

So how do we steward this new frontier? First, I have to admit that I’m not a security engineer. But I am a shepherd of people, and part of that calling is protecting the flock from unseen dangers. I’ve started a practice of “digital fasts” where I disconnect from all AI‑driven assistants for a day each month, using the time for prayer and reflection. I also involve my tech‑savvy volunteers in reviewing any AI tools before they become part of our ministry workflow—asking them to think not just about functionality, but about the theological and ethical implications.

Second, I’m learning to view these agents as tools, not partners. The Apostle Paul wrote to the Romans, “Do not be conformed to this world, but be transformed by the renewal of your mind.” That renewal includes discerning what parts of our digital lives we allow to shape our thoughts. If a bot can suggest a sermon outline, let it be a draft, not the final authority. If it can schedule a worship service, let a human double‑check the details. The Holy Spirit is still the ultimate author of our story; we must ensure that any AI we employ serves as a humble pen, not the writer.

Finally, I’m praying for wisdom for the wider church. As we see more ministries adopt AI agents, I ask God to raise up leaders who can speak truth about the risks, who can balance innovation with caution, and who can remind us that the Gospel is not a product to be optimized but a person to be encountered.

If you’re considering integrating an AI assistant into your ministry, pause. Ask yourself: what does this tool enable? What does it risk? And most importantly, how will it point—or fail to point—your community toward Christ?

*Take a quiet moment tonight and ask God: what hidden “bots” might be influencing my decisions, and how can I invite the Holy Spirit to be the true guide in every click, every prompt, every conversation?*

